{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/richard/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importer les librairies\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# nlp processing & corpus\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "## import punkt algo (spliting text into tokens)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Stylecloud viz\n",
    "import stylecloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import datas\n",
    "\n",
    "# local path from \n",
    "url = 'SMSSpamCollection.txt'\n",
    "\n",
    "# Read the text file into a DataFrame\n",
    "df = pd.read_csv(url, delimiter='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Label Ham & Spam*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.865937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>0.134063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  count_pct\n",
       "0   ham   0.865937\n",
       "1  spam   0.134063"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do they split ? \n",
    "count_val = df['label'].value_counts(normalize=True).to_frame().reset_index().rename(columns={'index':'label','label':'count_pct'})\n",
    "count_val\n",
    "# most of Ham "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = ham \n",
    "df_ham = df.copy()\n",
    "df_ham = df_ham.loc[df_ham['label'] =='ham']\n",
    "\n",
    "# label = spam\n",
    "df_spam = df.copy()\n",
    "df_spam = df_spam.loc[df_spam['label'] =='spam']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPAM Messages ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741633199464525"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_spam['message'].unique()) / len(df_spam['message'])\n",
    "# 87 % unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spam message present more than once are : \n",
    "spam_val_count = df_spam['message'].value_counts().to_frame().reset_index().rename(columns={'index':'msg','message':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present more than once, maybe supposed better to scam peole ? \n",
    "most_spam = spam_val_count.loc[spam_val_count['count']>1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most present words on message ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of stop_words from the english most common\n",
    "# list  \n",
    "stop_words = get_stop_words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom the stop_words list with \n",
    "\n",
    "# my_new_stop_word = []\n",
    "\n",
    "#stop_words.append('my_new_stop_word')\n",
    "#stop_words.remove('my_new_stop_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mb/fck_zr_56_n2ss6_66qj2cn40000gn/T/ipykernel_5200/1467994210.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the msg\n",
    "most_spam['tokens'] = most_spam['msg'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example for this token selection #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mb/fck_zr_56_n2ss6_66qj2cn40000gn/T/ipykernel_5200/1613764838.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/mb/fck_zr_56_n2ss6_66qj2cn40000gn/T/ipykernel_5200/1613764838.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "most_spam['tokens'] = most_spam['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Remove non-alphabetic words\n",
    "most_spam['tokens'] = most_spam['tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "# Compute word frequency\n",
    "words = []\n",
    "for msg in most_spam['tokens']:\n",
    "    for word in msg:\n",
    "        words.append(word)\n",
    "\n",
    "freq_dist = FreqDist(words)\n",
    "\n",
    "# Print the most common words\n",
    "freq_dist.most_common(10)\n",
    "\n",
    "# Convert FreqDist to DataFrame\n",
    "freq_word = pd.DataFrame(list(freq_dist.items()), columns=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>now</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Call</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ur</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>call</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FREE</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>txt</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>mobile</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "14      now     21\n",
       "68     Call     19\n",
       "47       ur     19\n",
       "1      call     19\n",
       "43     FREE     16\n",
       "51      txt     14\n",
       "118  mobile     14"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert FreqDist to DataFrame\n",
    "freq_word = pd.DataFrame(list(freq_dist.items()), columns=['word', 'count'])\n",
    "\n",
    "# sort_values & top 7 / 608 (1%)\n",
    "freq_word.sort_values(by='count',ascending=False).head(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stylecloud ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of words and their counts\n",
    "word_freq = dict(zip(freq_word['word'], freq_word['count']))\n",
    "\n",
    "# Generate a word cloud twitter output\n",
    "stylecloud.gen_stylecloud(text=word_freq, icon_name='fab fa-twitter', output_name='twitter.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud phone output\n",
    "stylecloud.gen_stylecloud(text=word_freq, icon_name='fas fa-mobile-alt', output_name='mobile.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definition ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def de la function most_common()\n",
    "## input \n",
    "## - dataset       = un dataset\n",
    "## - col_of_tokens = col of the dataset (whith tokens of the orignal messages)\n",
    "#\n",
    "#\n",
    "# Filtering while processing :  \n",
    "## Stop words + non alphabetic words - OFF \n",
    "#\n",
    "### RETURN dataset with word / count \n",
    "#\n",
    "def most_common(dataset,col_of_tokens):\n",
    "    dataset = dataset\n",
    "    col_of_tokens = str(col_of_tokens)\n",
    "\n",
    "    # Remove stop words\n",
    "    dataset[col_of_tokens] = most_spam[col_of_tokens].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "    # Remove non-alphabetic words\n",
    "    dataset[col_of_tokens] = dataset[col_of_tokens].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "    # Compute word frequency\n",
    "    words = []\n",
    "    for msg in dataset['tokens']:\n",
    "        for word in msg:\n",
    "            words.append(str(word))\n",
    "\n",
    "    freq_dist = FreqDist(words)\n",
    "\n",
    "    # Print the most common words\n",
    "    # freq_dist.most_common(10)\n",
    "\n",
    "    # Convert FreqDist to DataFrame\n",
    "    freq_word = pd.DataFrame(list(freq_dist.items()), columns=['word', 'count'])\n",
    "\n",
    "    # return du dataset\n",
    "    return freq_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply de function \n",
    "# my_df = most_common(most_spam,'tokens')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other spams ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_val_count['tokens'] = spam_val_count['msg'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have WON a guaranteed £1000 cash or a £2000 prize.To claim yr prize call our customer service representative on'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_val_count.iloc[648]['msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "spam_val_count['tokens'] = spam_val_count['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Remove non-alphabetic words\n",
    "spam_val_count['tokens'] = spam_val_count['tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "# Compute word frequency\n",
    "words = []\n",
    "for msg in spam_val_count['tokens']:\n",
    "    for word in msg:\n",
    "        words.append(word)\n",
    "\n",
    "freq_dist = FreqDist(words)\n",
    "\n",
    "# Print the most common words\n",
    "freq_dist.most_common(10)\n",
    "\n",
    "# Convert FreqDist to DataFrame\n",
    "freq_word = pd.DataFrame(list(freq_dist.items()), columns=['word', 'count'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wcs_22_django",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
